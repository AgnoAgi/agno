Question,Answer
What is the role of planning in LLM-powered autonomous agents?,"Planning involves breaking down large tasks into manageable subgoals and refining actions through self-reflection, enabling efficient task handling and iterative improvement."
How does Chain of Thought (CoT) prompting enhance model performance?,"CoT instructs models to think step by step, decomposing complex tasks into simpler steps, which improves reasoning and problem-solving capabilities."
What is the difference between zero-shot and few-shot learning in prompt engineering?,"Zero-shot learning provides the model with a task without prior examples, while few-shot learning includes a few examples to guide the model, often leading to better performance."
What are adversarial attacks on large language models (LLMs)?,"Adversarial attacks involve inputs designed to trigger LLMs to produce undesired outputs, potentially compromising safety and alignment."
How can token manipulation be used as an adversarial attack method?,"By altering a small fraction of tokens in the input text, attackers can cause the model to fail while maintaining the original semantic meaning."
What is the purpose of self-reflection in autonomous agents?,"Self-reflection allows agents to critique and learn from past actions, refining future decisions to improve task outcomes."
What is the significance of memory in LLM-powered autonomous agents?,"Memory enables agents to retain and recall information over time, supporting learning, adaptation, and informed decision-making."
How does Tree of Thoughts (ToT) extend the concept of Chain of Thought (CoT)?,"ToT explores multiple reasoning possibilities at each step, creating a tree structure that allows for broader exploration of potential solutions."
What is the purpose of self-consistency sampling in prompt engineering?,"Self-consistency sampling involves generating multiple outputs and selecting the most consistent one, enhancing the reliability of the model's responses."
How do gradient-based attacks differ from token manipulation attacks on LLMs?,"Gradient-based attacks rely on gradient signals to craft adversarial inputs, typically requiring white-box access, whereas token manipulation alters input tokens without gradient information, often in black-box settings."
